{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\josh_\\anaconda3\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\josh_\\anaconda3\\lib\\site-packages (0.21.0+cu118)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\josh_\\anaconda3\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\josh_\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\josh_\\anaconda3\\lib\\site-packages (10.4.0)\n",
      "Requirement already satisfied: nibabel in c:\\users\\josh_\\anaconda3\\lib\\site-packages (5.3.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\josh_\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: torchsummary in c:\\users\\josh_\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\josh_\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\josh_\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\josh_\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\josh_\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\josh_\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\josh_\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\josh_\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\josh_\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\josh_\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\josh_\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\josh_\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\josh_\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\josh_\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\josh_\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\josh_\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\josh_\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\josh_\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio matplotlib pillow nibabel numpy torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchsummary\n",
    "import nibabel as nib\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n",
      "Total GPU memory: 24.00 GB\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('CUDA is available. Using GPU.')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('CUDA is not available. Using CPU.')\n",
    "total_memory = torch.cuda.get_device_properties(device).total_memory\n",
    "print(f'Total GPU memory: {total_memory / (1024**3):.2f} GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping invalid label file: 20230507-fix\n",
      "Skipping invalid label file: labelsTr2200\n",
      "Skipping invalid label file: labelsTr2200.zip\n",
      "There are 500 scans and annotations in the dataset.\n"
     ]
    }
   ],
   "source": [
    "scan_path = 'E:/FLARE23/FLARE23_1501-2000'\n",
    "label_path = 'E:/FLARE23/MICCAI-FLARE23/labelsTr2200'\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "class AbdominalDataset(Dataset):\n",
    "    def __init__(self, scan_dir, label_dir, transforms, multiple, sample_size):\n",
    "        self.scan_dir = scan_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.transforms = transforms\n",
    "        self.multiple = multiple\n",
    "        self.sample_size = sample_size\n",
    "        self.prepare_files()\n",
    "\n",
    "    def prepare_files(self):\n",
    "        self.scan_idx = []\n",
    "        self.label_idx = []\n",
    "\n",
    "        # Process scan files\n",
    "        for scan_name in os.listdir(self.scan_dir):\n",
    "            try:\n",
    "                # Extract the integer part of the filename\n",
    "                scan_id = int(scan_name.split('_')[1])\n",
    "                self.scan_idx.append(scan_id)\n",
    "            except ValueError:\n",
    "                # Skip files that don't have an integer as the first part of the filename\n",
    "                print(f\"Skipping invalid scan file: {scan_name}\")\n",
    "                continue\n",
    "\n",
    "        # Process label files\n",
    "        for label_name in os.listdir(self.label_dir):\n",
    "            try:\n",
    "                # Extract the integer part of the filename\n",
    "                label_id = int(label_name.split('_')[0])\n",
    "                self.label_idx.append(label_id)\n",
    "            except ValueError:\n",
    "                # Skip files that don't have an integer as the first part of the filename\n",
    "                print(f\"Skipping invalid label file: {label_name}\")\n",
    "                continue\n",
    "\n",
    "        # Ensure that the scan and label indices are sorted\n",
    "        self.scan_idx.sort()\n",
    "        self.label_idx.sort()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.scan_idx)\n",
    "\n",
    "    def addZeroPadding(self, scan, label):\n",
    "        target_depth = (scan.shape[2] // self.multiple + 1) * self.multiple\n",
    "        pad_depth = target_depth - scan.shape[2]\n",
    "        pad_front = pad_depth // 2\n",
    "        pad_back = pad_depth - pad_front\n",
    "\n",
    "        scan_padded = np.pad(scan, ((0, 0), (0, 0), (pad_front, pad_back)), 'constant', constant_values=(0, 0))\n",
    "        label_padded = np.pad(label, ((0, 0), (0, 0), (pad_front, pad_back)), 'constant', constant_values=(0, 0))\n",
    "\n",
    "        return scan_padded, label_padded\n",
    "\n",
    "    def randSpatialSample(self, scan, label):\n",
    "        start_x = np.random.randint(0, scan.shape[0] - self.sample_size[0] + 1)\n",
    "        start_y = np.random.randint(0, scan.shape[1] - self.sample_size[1] + 1)\n",
    "        start_z = np.random.randint(0, scan.shape[2] - self.sample_size[2] + 1)\n",
    "\n",
    "        scan_sampled = scan[start_x:start_x + self.sample_size[0], start_y:start_y + self.sample_size[1], start_z:start_z + self.sample_size[2]]\n",
    "        label_sampled = label[start_x:start_x + self.sample_size[0], start_y:start_y + self.sample_size[1], start_z:start_z + self.sample_size[2]]\n",
    "\n",
    "        return scan_sampled, label_sampled\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        scan_loc = os.path.join(self.scan_dir, str(self.scan_idx[idx]) + '.nii.gz')\n",
    "        label_loc = os.path.join(self.label_dir, str(self.label_idx[idx]) + '.nii.gz')\n",
    "\n",
    "        scan_nii, label_nii = nib.load(scan_loc), nib.load(label_loc)\n",
    "        scan, label = scan_nii.get_fdata(), label_nii.get_fdata()\n",
    "\n",
    "        if scan.shape[2] % self.multiple != 0:\n",
    "            scan, label = self.addZeroPadding(scan, label)\n",
    "\n",
    "        rs_scan, rs_label = self.randSpatialSample(scan, label)\n",
    "\n",
    "        if self.transforms:\n",
    "            scan, label = self.transforms(rs_scan), self.transforms(rs_label)\n",
    "\n",
    "        return scan, label\n",
    "\n",
    "# Define the transforms\n",
    "abdominal_transforms = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Create the dataset\n",
    "abdominal_dataset = AbdominalDataset(scan_dir=scan_path, label_dir=label_path, transforms=abdominal_transforms, multiple=16, sample_size=(512, 512, 16))\n",
    "\n",
    "print(f\"There are {len(abdominal_dataset)} scans and annotations in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1      [-1, 32, 8, 256, 256]           2,080\n",
      "       BatchNorm3d-2      [-1, 32, 8, 256, 256]              64\n",
      "              ReLU-3      [-1, 32, 8, 256, 256]               0\n",
      "            Conv3d-4      [-1, 64, 4, 128, 128]         131,136\n",
      "       BatchNorm3d-5      [-1, 64, 4, 128, 128]             128\n",
      "              ReLU-6      [-1, 64, 4, 128, 128]               0\n",
      "            Conv3d-7       [-1, 128, 2, 64, 64]         524,416\n",
      "       BatchNorm3d-8       [-1, 128, 2, 64, 64]             256\n",
      "              ReLU-9       [-1, 128, 2, 64, 64]               0\n",
      "           Conv3d-10       [-1, 256, 1, 32, 32]       2,097,408\n",
      "      BatchNorm3d-11       [-1, 256, 1, 32, 32]             512\n",
      "             ReLU-12       [-1, 256, 1, 32, 32]               0\n",
      "  ConvTranspose3d-13       [-1, 128, 2, 64, 64]       2,097,280\n",
      "      BatchNorm3d-14       [-1, 128, 2, 64, 64]             256\n",
      "             ReLU-15       [-1, 128, 2, 64, 64]               0\n",
      "  ConvTranspose3d-16      [-1, 64, 4, 128, 128]         524,352\n",
      "      BatchNorm3d-17      [-1, 64, 4, 128, 128]             128\n",
      "             ReLU-18      [-1, 64, 4, 128, 128]               0\n",
      "  ConvTranspose3d-19      [-1, 32, 8, 256, 256]         131,104\n",
      "      BatchNorm3d-20      [-1, 32, 8, 256, 256]              64\n",
      "             ReLU-21      [-1, 32, 8, 256, 256]               0\n",
      "  ConvTranspose3d-22      [-1, 1, 16, 512, 512]           2,049\n",
      "          Sigmoid-23      [-1, 1, 16, 512, 512]               0\n",
      "================================================================\n",
      "Total params: 5,511,233\n",
      "Trainable params: 5,511,233\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 16.00\n",
      "Forward/backward pass size (MB): 1078.00\n",
      "Params size (MB): 21.02\n",
      "Estimated Total Size (MB): 1115.02\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class MaskedAutoencoder3D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, hidden_dim):\n",
    "        super(MaskedAutoencoder3D, self).__init__()\n",
    "\n",
    "        # Encoder part (Conv3D Layers with BatchNorm3D)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, hidden_dim, kernel_size=4, stride=2, padding=1),  # Output: (hidden_dim, 8, 256, 256)\n",
    "            nn.BatchNorm3d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv3d(hidden_dim, hidden_dim * 2, kernel_size=4, stride=2, padding=1),  # Output: (hidden_dim*2, 4, 128, 128)\n",
    "            nn.BatchNorm3d(hidden_dim * 2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv3d(hidden_dim * 2, hidden_dim * 4, kernel_size=4, stride=2, padding=1),  # Output: (hidden_dim*4, 2, 64, 64)\n",
    "            nn.BatchNorm3d(hidden_dim * 4),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Removed some more convolutions to keep dimensions higher\n",
    "            nn.Conv3d(hidden_dim * 4, hidden_dim * 8, kernel_size=4, stride=2, padding=1),  # Output: (hidden_dim*8, 1, 32, 32)\n",
    "            nn.BatchNorm3d(hidden_dim * 8),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Decoder part (ConvTranspose3D Layers with BatchNorm3D)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose3d(hidden_dim * 8, hidden_dim * 4, kernel_size=4, stride=2, padding=1),  # Output: (hidden_dim*4, 2, 64, 64)\n",
    "            nn.BatchNorm3d(hidden_dim * 4),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose3d(hidden_dim * 4, hidden_dim * 2, kernel_size=4, stride=2, padding=1),  # Output: (hidden_dim*2, 4, 128, 128)\n",
    "            nn.BatchNorm3d(hidden_dim * 2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose3d(hidden_dim * 2, hidden_dim, kernel_size=4, stride=2, padding=1),  # Output: (hidden_dim, 8, 256, 256)\n",
    "            nn.BatchNorm3d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose3d(hidden_dim, out_channels, kernel_size=4, stride=2, padding=1),  # Output: (out_channels, 16, 512, 512)\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# creating the model\n",
    "in_channels = 1\n",
    "out_channels = 1\n",
    "hidden_dim = 32\n",
    "\n",
    "model = MaskedAutoencoder3D(in_channels, out_channels, hidden_dim)\n",
    "\n",
    "torchsummary.summary(model.cuda(), (in_channels, 16, 512, 512))  # input shape: (in_channels, depth, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(abdominal_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[0;32m      5\u001b[0m test_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(abdominal_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m test_dataloader:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of X [N, C, H, W]: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of y: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\josh_\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    714\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\josh_\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\josh_\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[4], line 75\u001b[0m, in \u001b[0;36mAbdominalDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m     74\u001b[0m     scan_loc \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_dir, \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_idx[idx]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.nii.gz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 75\u001b[0m     label_loc \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_dir, \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_idx[idx]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.nii.gz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     77\u001b[0m     scan_nii, label_nii \u001b[38;5;241m=\u001b[39m nib\u001b[38;5;241m.\u001b[39mload(scan_loc), nib\u001b[38;5;241m.\u001b[39mload(label_loc)\n\u001b[0;32m     78\u001b[0m     scan, label \u001b[38;5;241m=\u001b[39m scan_nii\u001b[38;5;241m.\u001b[39mget_fdata(), label_nii\u001b[38;5;241m.\u001b[39mget_fdata()\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(abdominal_dataset, batch_size=batch_size)\n",
    "#test_dataloader = DataLoader(abdominal_dataset, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     train(train_dataloader, model, loss_fn, optimizer)\n\u001b[0;32m      5\u001b[0m     test(test_dataloader, model, loss_fn)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[0;32m      2\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[0;32m      5\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Compute prediction error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\josh_\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    714\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\josh_\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\josh_\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[4], line 75\u001b[0m, in \u001b[0;36mAbdominalDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m     74\u001b[0m     scan_loc \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_dir, \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_idx[idx]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.nii.gz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 75\u001b[0m     label_loc \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_dir, \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_idx[idx]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.nii.gz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     77\u001b[0m     scan_nii, label_nii \u001b[38;5;241m=\u001b[39m nib\u001b[38;5;241m.\u001b[39mload(scan_loc), nib\u001b[38;5;241m.\u001b[39mload(label_loc)\n\u001b[0;32m     78\u001b[0m     scan, label \u001b[38;5;241m=\u001b[39m scan_nii\u001b[38;5;241m.\u001b[39mget_fdata(), label_nii\u001b[38;5;241m.\u001b[39mget_fdata()\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
